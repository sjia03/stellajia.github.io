<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen;
      padding: 2rem;
    }
    nav {
      display: flex;
      justify-content: space-between;
      margin-bottom: 2rem;
    }
    nav a {
      margin-left: 1rem;
      text-decoration: none;
      color: #333;
      font-weight: 500;
    }
    h1 {
      font-size: 2.5rem;
    }
    table {
      width: 100%;
      border-collapse: collapse;
      margin-top: 2rem;
    }
    th, td {
      padding: 1rem;
      border-bottom: 1px solid #ddd;
      vertical-align: top;
    }
    .tag {
      display: inline-block;
      background: #eee;
      border-radius: 6px;
      padding: 0.2rem 0.5rem;
      margin: 0.2rem;
      font-size: 0.8rem;
    }
    .container {
      max-width: 1000px;
      margin: 0 auto;
      padding: 0 1.5rem;
    }
  </style>
</head>
<body>
  <div class="container">
    <title>Research</title>
    <nav>
        <div><a href="index.html">Home</a></div>
        <div>
        <a href="books.html">Books</a>
        <a href="hikes.html">Hikes</a>
        <a href="research.html">Research</a>
        </div>
    </nav>


    <h1>Research</h1>
    <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Topics</th>
        <th>URL</th>
        <th>Abstract</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Cloze Encounters: The Impact of Pirated Data Access on LLM Performance</td>
        <td>
          <span class="tag">innovation</span><span class="tag">genai</span><span class="tag">copyright</span>
        </td>
        <td>www.nber.org</td>
        <td>Large Language Models (LLMs) have demonstrated remarkable capabilities in text generation, but their performance may be influenced by the datasets on which they are trained, including potentially unauthorized or pirated content. We investigate the extent to which data access through pirated books influences LLM responses. We test the performance of leading foundation models (GPT, Claude, Llama, and Gemini) on a set of books that were and were not included in the Books3 dataset, which contains full-text pirated books and could be used for LLM training. We assess book-level performance using the “name cloze” word-prediction task. To examine the causal effect of Books3 inclusion we employ an instrumental variables strategy that exploits the pattern of book publication years in the Books3 dataset. In our sample of 12,916 books, we find significant improvements in LLM name cloze accuracy on books available within the Books3 dataset compared to those not present in these data. These effects are more pronounced for less popular books as compared to more popular books and vary across leading models. These findings have crucial implications for the economics of digitization, copyright policy, and the design and training of AI systems.
        </td>
      </tr>
      <tr>
        <td>The Crowdless Future? Generative AI and Creative Problem-Solving</td>
        <td>
          <span class="tag">creativity</span><span class="tag">genai</span>
        </td>
        <td>pubsonline.informs.org</td>
        <td>The rapid advances in generative artificial intelligence (AI) open up attractive opportunities for creative problem-solving through human-guided AI partnerships. To explore this potential, we initiated a crowdsourcing challenge focused on sustainable, circular economy business ideas generated by the human crowd (HC) and collaborative human-AI efforts using two alternative forms of solution search. The challenge attracted 125 global solvers from various industries, and we used strategic prompt engineering to generate the human-AI solutions. We recruited 300 external human evaluators to judge a randomized selection of 13 out of 234 solutions, totaling 3,900 evaluator-solution pairs. Our results indicate that while human crowd solutions exhibited higher novelty—both on average and for highly novel outcomes—human-AI solutions demonstrated superior strategic viability, financial and environmental value, and overall quality. Notably, human-AI solutions cocreated through differentiated search, where human-guided prompts instructed the large language model to sequentially generate outputs distinct from previous iterations, outperformed solutions generated through independent search. By incorporating “AI in the loop” into human-centered creative problem-solving, our study demonstrates a scalable, cost-effective approach to augment the early innovation phases and lays the groundwork for investigating how integrating human-AI solution search processes can drive more impactful innovations.</td>
      </tr>
      <tr>
        <td>Influence of Generative AI on Knowledge Dynamics in Stack Exchange</td>
        <td>
          <span class="tag">innovation</span><span class="tag">genai</span><span class="tag">knowledge</span>
        </td>
        <td>github.com</td>
        <td>Examines how AI systems like ChatGPT alter online knowledge ecosystems. Stack Exchange is used to evaluate pre- and post-AI discourse shifts...</td>
      </tr>
    </tbody>
  </table>
  </div>
</body>
</html>
